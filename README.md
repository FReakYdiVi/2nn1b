# Conditional Varitional Autoencoder for Deep generative models of Subsurface model

This is pytorch implementation of:
* Conditional Varitional Autoencoders(CVAE) using Convulution network 

## What is a CVAE?

A **CVAE** is a form of variational autoencoder that is
conditioned on an observation, where in our case the observation is a function y.

The autoencoders from which variational autoencoders
are derived are typically used for problems involving
image reconstruction and/or dimensionality reduction.

An Autoencoders is composed of two neural netwroks **Encoder** and **Decoder** where an Encoders takes an input prededined by the user and convert it into a low dimensionality space known as **latent space** and This latent space is passed through decoder to convert it to the original input size.

Additionally,
the decoder simultaneously learns to decode the latent
space representation and reconstruct that data back to
its original input. 

In **Varitional Autoencoders** this latent space is interpreted as a set of parameters governing statistical distributions In proceeding to the decoder
network, samples from the latent space (z) are randomly
drawn from these distributions and fed into the decoder,
therefore adding an element of variation into the process.
So in this way Varitional Autoencoders are used for generating samples of input which are similar to the given input(x) and **Conditional Autoencoder** is one step up in which we also add a condition that is to be fulfilled and this condition is passes through both encoder and decoder

THERE ARE MANY RESULTS THAT I HAD GOT BUT I HAD INCLUDED VERY FEW BEST RESULTS ONLY




# Referrals 
for data_1 please refer to [Starter_Notebook](https://github.com/FReakYdiVi/2nn1b/blob/main/Starter%20Notebook.ipynb) 

for data_2 please refer to [Starter Notebook1](https://github.com/FReakYdiVi/2nn1b/blob/main/Starter%20Notebook1.ipynb)


## Model Structure


| Neural Network | Number of CNN Layers | Number of Linear Layers | Activation Function       |
|-----------|----------------------|-------------------------|---------------------------|
| Encoder   | 2                    | 1                       |  ReLU     |
| Decoder   | 2                    | 1                       | LeakyReLU (0.01 |


### Network Structure

Refer to [CVAE_example.py](https://github.com/FReakYdiVi/2nn1b/blob/main/CVAE_example.py) for model code and structure names as CVAE 


## Model Structure related to research paper 

<img width="394" alt="Screenshot 2024-02-09 at 2 45 54 PM" src="https://github.com/FReakYdiVi/2nn1b/assets/129744247/33204703-dd77-45f3-a7bd-f4c7df1176b8">

### Explanation
The encoder (denoted by qφ(z|x) with
φ the abbreviation of biases and weights of the encoder’s
neural network) compress the input data x into the latent
layer z of smaller dimensions than the ones of x, and then
the decoder (denoted by pθ(˜x|z) with θ the abbreviation
of biases and weights of the decoder’s neural network)
un-compress the latent layer back to the final result ˜x of
the same dimension as x. and Due to the additional encoder, we now have two latent
vectors z1 and z2 as shown in img
). We can then introduce the latent loss to measure their difference. For for CVAE it is the KL divergence between the Gaussian distributions generated by the two encoders. On the
other hand, the reconstruction loss is the MSE between the x and reconstructed x and cross entropy loss for y and reconstructed y


## Model Structure related to research paper 

| Component   | Number of CNN Layers | Number of Linear Layers | Activation Functions Used |
|-------------|----------------------|-------------------------|---------------------------|
| Encoder1    | 2                    | 2                      | ReLu          |
| Encoder2    | 0                    | 2                       | -          |
| Decoder     | 2                    | 1                       | LeakyRelu          |

### Network Structure

Refer to [CVAE_example.py](https://github.com/FReakYdiVi/2nn1b/blob/main/CVAE_example.py) for model code and structure names as CVAE_re

If you want to know more about the structure , just read this [reaserch paper](https://arxiv.org/abs/2101.06685
)

## Usage Of Libararies
### pre requistes
1. pytorch , numpy ,matplot , pandas
### Built In Library
1. CVAE_example, CVAE_functions 


## Results

All result and scores for each model for each data is clarified in the each notebook

### Findings 

Some of the findings that improved my model are-
 1. Concatenating the input and condition data in the encoder part improved my scores and just after that changing the activation function to leaky relu was a great choice in the every model.

 2. Adding one more layer of convulution also improved my scores but not that much and to avoid overfitting i just batch normalisation for each layer.

 3. Using cross entropy loss for y_loss for the model that refer to research paper was a great choice as it greatly improved my recontruction errors.

## Blockers

This was tough and new kind of problem for me as it was related to geneartive ai and through this journey i got to many insights towards how autoencoders work or particulary how Conditional variational autoencoders work at generating samples and there were many hurdles towards how to make this project a better performer so I am gonna share a few and how i solved it -

1. the first problem was with **tuning of hyperparameters**
and I was using **optuna** for this but i was not getting good results with the optuna so then i thought to drop the idea of hyperparameter tuning and move towards upgrading the model structure of given model and thought i would be more relelvant.

2. I just modify the given model by adding leaky relu and it greatly reduces the overall loss of the model and secondly i also added condition to the encoder part as it was firstly not passing through encoder.

3. I also modify the given structure by adding one more convulution layer and you can see this code  in [CVAE_example.py](https://github.com/FReakYdiVi/2nn1b/blob/main/CVAE_example.py)

4. I took on to build a model like one from a research paper, which had two encoders and one decoder. This task was very hard but exciting. I changed the **y_loss to use cross-entropy**, which worked better than the old method. Making this model took a lot of time and effort because it was complicated. In the end, I was able to create it, and I learned a lot from the experience but it is a baseline model and i can still make it more better and I think so It would be the **best model across all models**
